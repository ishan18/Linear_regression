# -*- coding: utf-8 -*-
"""
Created on Thu Dec 20 13:29:06 2018

@author: ISHAN
"""
import numpy as np
import math

m=118 #input('Total no. of data sets? ') #total no. of data sets
m=int(m)
n=input('How many training examples you will provide? ')
n=int(n) #total no. of training examples
n2=input('How many features you will provide? ') #total no. of features
n2=int(n2)
data=np.array([0.051267,0.69956,1,
-0.092742,0.68494,1,
-0.21371,0.69225,1,
-0.375,0.50219,1,
-0.51325,0.46564,1,
-0.52477,0.2098,1,
-0.39804,0.034357,1,
-0.30588,-0.19225,1,
0.016705,-0.40424,1,
0.13191,-0.51389,1,
0.38537,-0.56506,1,
0.52938,-0.5212,1,
0.63882,-0.24342,1,
0.73675,-0.18494,1,
0.54666,0.48757,1,
0.322,0.5826,1,
0.16647,0.53874,1,
-0.046659,0.81652,1,
-0.17339,0.69956,1,
-0.47869,0.63377,1,
-0.60541,0.59722,1,
-0.62846,0.33406,1,
-0.59389,0.005117,1,
-0.42108,-0.27266,1,
-0.11578,-0.39693,1,
0.20104,-0.60161,1,
0.46601,-0.53582,1,
0.67339,-0.53582,1,
-0.13882,0.54605,1,
-0.29435,0.77997,1,
-0.26555,0.96272,1,
-0.16187,0.8019,1,
-0.17339,0.64839,1,
-0.28283,0.47295,1,
-0.36348,0.31213,1,
-0.30012,0.027047,1,
-0.23675,-0.21418,1,
-0.06394,-0.18494,1,
0.062788,-0.16301,1,
0.22984,-0.41155,1,
0.2932,-0.2288,1,
0.48329,-0.18494,1,
0.64459,-0.14108,1,
0.46025,0.012427,1,
0.6273,0.15863,1,
0.57546,0.26827,1,
0.72523,0.44371,1,
0.22408,0.52412,1,
0.44297,0.67032,1,
0.322,0.69225,1,
0.13767,0.57529,1,
-0.0063364,0.39985,1,
-0.092742,0.55336,1,
-0.20795,0.35599,1,
-0.20795,0.17325,1,
-0.43836,0.21711,1,
-0.21947,-0.016813,1,
-0.13882,-0.27266,1,
0.18376,0.93348,0,
0.22408,0.77997,0,
0.29896,0.61915,0,
0.50634,0.75804,0,
0.61578,0.7288,0,
0.60426,0.59722,0,
0.76555,0.50219,0,
0.92684,0.3633,0,
0.82316,0.27558,0,
0.96141,0.085526,0,
0.93836,0.012427,0,
0.86348,-0.082602,0,
0.89804,-0.20687,0,
0.85196,-0.36769,0,
0.82892,-0.5212,0,
0.79435,-0.55775,0,
0.59274,-0.7405,0,
0.51786,-0.5943,0,
0.46601,-0.41886,0,
0.35081,-0.57968,0,
0.28744,-0.76974,0,
0.085829,-0.75512,0,
0.14919,-0.57968,0,
-0.13306,-0.4481,0,
-0.40956,-0.41155,0,
-0.39228,-0.25804,0,
-0.74366,-0.25804,0,
-0.69758,0.041667,0,
-0.75518,0.2902,0,
-0.69758,0.68494,0,
-0.4038,0.70687,0,
-0.38076,0.91886,0,
-0.50749,0.90424,0,
-0.54781,0.70687,0,
0.10311,0.77997,0,
0.057028,0.91886,0,
-0.10426,0.99196,0,
-0.081221,1.1089,0,
0.28744,1.087,0,
0.39689,0.82383,0,
0.63882,0.88962,0,
0.82316,0.66301,0,
0.67339,0.64108,0,
1.0709,0.10015,0,
-0.046659,-0.57968,0,
-0.23675,-0.63816,0,
-0.15035,-0.36769,0,
-0.49021,-0.3019,0,
-0.46717,-0.13377,0,
-0.28859,-0.060673,0,
-0.61118,-0.067982,0,
-0.66302,-0.21418,0,
-0.59965,-0.41886,0,
-0.72638,-0.082602,0,
-0.83007,0.31213,0,
-0.72062,0.53874,0,
-0.59389,0.49488,0,
-0.48445,0.99927,0,
-0.0063364,0.99927,0,
0.63265,-0.030612,0])
def feat_scale(X,n,n2):
    f=np.random.rand(n,n2)
    for a in range(n2):
        f.T[a]=X.max(axis=0)[a]
    g=np.random.rand(n,n2)
    for a in range(n2):
        g.T[a]=X.min(axis=0)[a]
    h=np.random.rand(n,n2)
    for a in range(n2):
        h.T[a]=np.mean(X,axis=0)[a]
    X=np.divide((X-h),(f-g))
    return X;
def logistic_reg_grad_descent(data,m,n,n2):
    data=data.reshape(m,n2+1)
    data1=np.delete(data,n2,axis=1)
    X=data1[0:n]
    #X=feat_scale(X,n,n2)
    X=np.concatenate((np.ones((n,1)),X),axis=1)
    Y=data[0:n,n2]
    theta=np.random.rand(n2+1,1)*10
    iteration=input('How many iterations? ')
    iteration=int(iteration)
    p=input('Enter alpha value: ')
    p=float(p)
    #j=input('Enter lambda value(for regularisation): ' )
    #j=float(j)
    theta1=theta
    for i in range(iteration):
        for k in range(n2):
             s=0
             for l in range(n):
                 t=float(np.dot(X[l],theta))
                 h=1/(1+math.exp(-1*t))
                 s=s+(h-Y[l])*X[l:l+1,k]
             theta1[k]=theta[k]-(p/n)*s
             theta=theta1
    Y1=np.random.rand(m-n,1)
    X1=data1[n:m]
    #X1=feat_scale(X1,m-n,n2)
    X1=np.concatenate((np.ones((m-n,1)),X1),axis=1)
    for r in range(m-n):
        if np.dot(X1[r],theta)>=0:
            Y1[r]=1
        else:
            Y1[r]=0
    Y=data[n:,n2]
    #to calculate accuracy
    accuracy=np.random.rand(m-n,1)
    for b in range(m-n):
         if Y1[b]==Y[b]:
             accuracy[b]=1
         else:
             accuracy[b]=0
    accuracy=np.sum(accuracy)*100/(m-n)
    return accuracy;

accuracy=logistic_reg_grad_descent(data,m,n,n2)
print(accuracy)
